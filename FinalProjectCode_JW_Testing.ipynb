{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Final Project Code\n",
    "# Amazon Product Review Aspect-Based Sentiment\n",
    "## Jennifer Mahle and Joanna Wang (Sections 3 and 1, respectively) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6739580</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 25, 2017</td>\n",
       "      <td>A1OOVLE2KZ6KGA</td>\n",
       "      <td>B01HJCN1EI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Puddzee</td>\n",
       "      <td>These are my favorite charging cords for a few...</td>\n",
       "      <td>Worth the price.</td>\n",
       "      <td>1500940800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739581</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>04 4, 2017</td>\n",
       "      <td>A77K1B31UAQ29</td>\n",
       "      <td>B01HJCN1EI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>addictedtoreading</td>\n",
       "      <td>Update....after 2 months of gentle use, cable ...</td>\n",
       "      <td>UPDATE...BREAKS AND SLOW CHARGING</td>\n",
       "      <td>1491264000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739582</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>07 8, 2017</td>\n",
       "      <td>A2SVXUVUAWUDK2</td>\n",
       "      <td>B01HJH42KU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>These are okay. The connection becomes very if...</td>\n",
       "      <td>Hope this makes sense. You'd understand if you...</td>\n",
       "      <td>1499472000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739583</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>05 21, 2017</td>\n",
       "      <td>A12E1JGKV0ETAB</td>\n",
       "      <td>B01HJH42KU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>I liked the length and the product at first bu...</td>\n",
       "      <td>Lost ability to connect.</td>\n",
       "      <td>1495324800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739584</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 26, 2017</td>\n",
       "      <td>A1HKXEX8BEQC2E</td>\n",
       "      <td>B01HJH40WU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dasha stephens</td>\n",
       "      <td>not holding up over time :(</td>\n",
       "      <td>not holding up over time :(</td>\n",
       "      <td>1498435200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739585</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>03 21, 2017</td>\n",
       "      <td>A33MAQA919J2V8</td>\n",
       "      <td>B01HJH40WU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Wurm</td>\n",
       "      <td>These seem like quality USB cables, time will ...</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1490054400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739586</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>01 9, 2017</td>\n",
       "      <td>A1AKHSCPD1BHM4</td>\n",
       "      <td>B01HJH40WU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C.L Momof3</td>\n",
       "      <td>Works great, love the longer cord. As with any...</td>\n",
       "      <td>Nice long cord</td>\n",
       "      <td>1483920000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739587</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12 1, 2016</td>\n",
       "      <td>A2HUZO7MQAY5I2</td>\n",
       "      <td>B01HJH40WU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>michael clontz</td>\n",
       "      <td>Ok here is an odd thing that happened to me, I...</td>\n",
       "      <td>Not the correct product as linked in the sale.</td>\n",
       "      <td>1480550400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739588</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11 29, 2016</td>\n",
       "      <td>AJJ7VX2L91X2W</td>\n",
       "      <td>B01HJH40WU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Faith</td>\n",
       "      <td>Works well.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1480377600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6739589</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>03 31, 2017</td>\n",
       "      <td>A1FGCIRPRNZWD5</td>\n",
       "      <td>B01HJF704M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brando</td>\n",
       "      <td>I have it plugged into a usb extension on my g...</td>\n",
       "      <td>Works well enough..</td>\n",
       "      <td>1490918400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "6739580        5  NaN      True  07 25, 2017  A1OOVLE2KZ6KGA  B01HJCN1EI   \n",
       "6739581        1  NaN      True   04 4, 2017   A77K1B31UAQ29  B01HJCN1EI   \n",
       "6739582        3  NaN      True   07 8, 2017  A2SVXUVUAWUDK2  B01HJH42KU   \n",
       "6739583        2  NaN      True  05 21, 2017  A12E1JGKV0ETAB  B01HJH42KU   \n",
       "6739584        3  NaN      True  06 26, 2017  A1HKXEX8BEQC2E  B01HJH40WU   \n",
       "6739585        4  NaN      True  03 21, 2017  A33MAQA919J2V8  B01HJH40WU   \n",
       "6739586        4  NaN      True   01 9, 2017  A1AKHSCPD1BHM4  B01HJH40WU   \n",
       "6739587        5    2      True   12 1, 2016  A2HUZO7MQAY5I2  B01HJH40WU   \n",
       "6739588        5    2      True  11 29, 2016   AJJ7VX2L91X2W  B01HJH40WU   \n",
       "6739589        5  NaN      True  03 31, 2017  A1FGCIRPRNZWD5  B01HJF704M   \n",
       "\n",
       "        style       reviewerName  \\\n",
       "6739580   NaN            Puddzee   \n",
       "6739581   NaN  addictedtoreading   \n",
       "6739582   NaN             Andrew   \n",
       "6739583   NaN         John Adams   \n",
       "6739584   NaN     Dasha stephens   \n",
       "6739585   NaN          Kurt Wurm   \n",
       "6739586   NaN         C.L Momof3   \n",
       "6739587   NaN     michael clontz   \n",
       "6739588   NaN              Faith   \n",
       "6739589   NaN             Brando   \n",
       "\n",
       "                                                reviewText  \\\n",
       "6739580  These are my favorite charging cords for a few...   \n",
       "6739581  Update....after 2 months of gentle use, cable ...   \n",
       "6739582  These are okay. The connection becomes very if...   \n",
       "6739583  I liked the length and the product at first bu...   \n",
       "6739584                        not holding up over time :(   \n",
       "6739585  These seem like quality USB cables, time will ...   \n",
       "6739586  Works great, love the longer cord. As with any...   \n",
       "6739587  Ok here is an odd thing that happened to me, I...   \n",
       "6739588                                        Works well.   \n",
       "6739589  I have it plugged into a usb extension on my g...   \n",
       "\n",
       "                                                   summary  unixReviewTime  \\\n",
       "6739580                                   Worth the price.      1500940800   \n",
       "6739581                  UPDATE...BREAKS AND SLOW CHARGING      1491264000   \n",
       "6739582  Hope this makes sense. You'd understand if you...      1499472000   \n",
       "6739583                           Lost ability to connect.      1495324800   \n",
       "6739584                        not holding up over time :(      1498435200   \n",
       "6739585                                         Four Stars      1490054400   \n",
       "6739586                                     Nice long cord      1483920000   \n",
       "6739587     Not the correct product as linked in the sale.      1480550400   \n",
       "6739588                                         Five Stars      1480377600   \n",
       "6739589                                Works well enough..      1490918400   \n",
       "\n",
       "        image  \n",
       "6739580   NaN  \n",
       "6739581   NaN  \n",
       "6739582   NaN  \n",
       "6739583   NaN  \n",
       "6739584   NaN  \n",
       "6739585   NaN  \n",
       "6739586   NaN  \n",
       "6739587   NaN  \n",
       "6739588   NaN  \n",
       "6739589   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6739590 entries, 0 to 6739589\n",
      "Data columns (total 12 columns):\n",
      "overall           int64\n",
      "vote              object\n",
      "verified          bool\n",
      "reviewTime        object\n",
      "reviewerID        object\n",
      "asin              object\n",
      "style             object\n",
      "reviewerName      object\n",
      "reviewText        object\n",
      "summary           object\n",
      "unixReviewTime    int64\n",
      "image             object\n",
      "dtypes: bool(1), int64(2), object(9)\n",
      "memory usage: 572.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset = \"Electronics_5.json\"\n",
    "\n",
    "if os.path.isfile(dataset):\n",
    "    df = pd.read_json(\"Electronics_5.json\", lines=True)\n",
    "else:\n",
    "    url = r\"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Electronics_5.json.gz\"\n",
    "    df = pd.read_json(url, compression='gzip', lines=True)\n",
    "\n",
    "display(df.tail(10))\n",
    "df.shape\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6738237, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['reviewText'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini= df.sample(n=600)\n",
    "df_mini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3546656, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.dropna(subset=['style'])\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 600 entries, 3612555 to 1340345\n",
      "Data columns (total 12 columns):\n",
      "overall           600 non-null int64\n",
      "vote              65 non-null object\n",
      "verified          600 non-null bool\n",
      "reviewTime        600 non-null object\n",
      "reviewerID        600 non-null object\n",
      "asin              600 non-null object\n",
      "style             314 non-null object\n",
      "reviewerName      600 non-null object\n",
      "reviewText        600 non-null object\n",
      "summary           600 non-null object\n",
      "unixReviewTime    600 non-null int64\n",
      "image             9 non-null object\n",
      "dtypes: bool(1), int64(2), object(9)\n",
      "memory usage: 56.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_mini.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow-gpu in /home/wangjia/anaconda3/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (3.11.3)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (1.27.2)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/wangjia/anaconda3/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow-gpu) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /home/wangjia/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: tensorflow-hub in /home/wangjia/anaconda3/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-hub) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-hub) (1.17.2)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from tensorflow-hub) (3.11.3)\n",
      "Requirement already satisfied: setuptools in /home/wangjia/anaconda3/lib/python3.7/site-packages (from protobuf>=3.4.0->tensorflow-hub) (41.4.0)\n",
      "Requirement already satisfied: seaborn in /home/wangjia/anaconda3/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from seaborn) (1.17.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/wangjia/anaconda3/lib/python3.7/site-packages (from pandas>=0.15.2->seaborn) (2019.3)\n",
      "Requirement already satisfied: six in /home/wangjia/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=1.4.3->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/wangjia/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "# Remove ## from lines starting with ! and run them the first time to install necessary packages \n",
    "\n",
    "##%%capture\n",
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "# Install TF-Hub.\n",
    "!pip3 install tensorflow-hub\n",
    "!pip3 install seaborn\n",
    "#@title Load the Universal Sentence Encoder's TF Hub module\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "  return model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing data, using \"overall\" as the target variable\n",
    "y=df_mini.overall\n",
    "x=df_mini.drop('overall',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (480, 11)\n",
      "y_train shape: (480,)\n",
      "\n",
      "x_test shape: (120, 11)\n",
      "y_test shape: (120,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "print(\"x_train shape: {}\".format(x_train.shape), end='\\n')\n",
    "print(\"y_train shape: {}\".format(y_train.shape), end='\\n\\n')\n",
    "print(\"x_test shape: {}\".format(x_test.shape), end='\\n')\n",
    "print(\"y_test shape: {}\".format(y_test.shape), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_messages = x_train.reviewText\n",
    "message_embeddings = embed(reviews_messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bfe6b4d1faeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_embedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Message: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_messages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Embedding size: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   message_embedding_snippet = \", \".join(\n\u001b[1;32m      5\u001b[0m       (str(x) for x in message_embedding[:3]))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "  print(\"Message: {}\".format(reviews_messages[i]))\n",
    "  print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "  message_embedding_snippet = \", \".join(\n",
    "      (str(x) for x in message_embedding[:3]))\n",
    "  print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Vectorize X_train\n",
    "vectorizer = CountVectorizer(min_df=1).fit(x_train)\n",
    "X_train = vectorizer.transform(x_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#BoW\n",
    "def apply_bow(final_df,ngram_range=(1,1)):\n",
    "    count_vect = CountVectorizer(ngram_range=ngram_range) #in scikit-learn\n",
    "    final_counts = count_vect.fit_transform(final_df['CleanedText'].values)\n",
    "    print(\"the type of count vectorizer \",type(final_counts))\n",
    "    print(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\n",
    "    print(\"the number of unique words \", final_counts.get_shape()[1])\n",
    "    return final_counts  \n",
    "apply_bow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
